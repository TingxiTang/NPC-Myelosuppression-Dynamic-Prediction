import streamlit as st
import pandas as pd
import numpy as np
import joblib
import shap
import traceback
import io
import datetime
import os
import sys
import pickle
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image as ReportLabImage
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors
from pathlib import Path

# ==========================================
# 1. æ ¸å¿ƒç±»å®šä¹‰ (å¿…é¡»åœ¨ pickle åŠ è½½å‰å®šä¹‰)
# ==========================================

class PlattScalingCalibrator:
    """
    æ‰‹åŠ¨å®ç° Platt Scaling æ¦‚ç‡æ ¡å‡†
    """
    def __init__(self, base_model):
        self.base_model = base_model
        self.platt_lr = None

    def fit(self, X, y):
        pass

    def predict_proba(self, X):
        """æ ¡å‡†åçš„æ¦‚ç‡é¢„æµ‹"""
        if hasattr(self.base_model, "predict_proba"):
            raw_probs = self.base_model.predict_proba(X)[:, 1]
        else:
            raw_probs = self.base_model.predict(X)

        if self.platt_lr is not None:
            # å¦‚æœå·²æœ‰æ ¡å‡†å™¨ï¼Œä½¿ç”¨å®ƒ
            calibrated_probs = self.platt_lr.predict_proba(raw_probs.reshape(-1, 1))
            return calibrated_probs
        else:
            # å¦‚æœæ²¡æœ‰æ ¡å‡†å™¨ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰ï¼Œæ‰‹åŠ¨æ„å»º (N, 2) æ ¼å¼è¿”å›
            return np.column_stack((1 - raw_probs, raw_probs))

# æ³¨å…¥åˆ° sys.modules ç¡®ä¿ pickle å¯ä»¥æ‰¾åˆ°è¯¥ç±»
sys.modules['__main__'].PlattScalingCalibrator = PlattScalingCalibrator


# ==========================================
# 2. é…ç½®ä¸å¸¸é‡
# ==========================================

st.set_page_config(
    page_title="éª¨é«“æŠ‘åˆ¶é£é™©é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide"
)

# ä½ çš„å·¥ä½œç›®å½•
WORKING_DIR = Path(__file__).parent.absolute()

# macOS ä¸­æ–‡å­—ä½“è·¯å¾„ (ç”¨äºè§£å†³ PDF ä¹±ç )
FONT_PATH = "/System/Library/Fonts/PingFang.ttc"
if not os.path.exists(FONT_PATH):
    # å¤‡ç”¨è·¯å¾„
    FONT_PATH = "/System/Library/Fonts/STHeiti Light.ttc"

# ==========================================
# 3. è¾…åŠ©å‡½æ•°ï¼šPDF ç”Ÿæˆ (è§£å†³ä¹±ç )
# ==========================================

def register_chinese_font():
    """æ³¨å†Œä¸­æ–‡å­—ä½“"""
    try:
        if os.path.exists(FONT_PATH):
            pdfmetrics.registerFont(TTFont('ChineseFont', FONT_PATH))
            return True
        return False
    except Exception as e:
        print(f"å­—ä½“æ³¨å†Œå¤±è´¥: {e}")
        return False

def create_pdf_report(patient_data, selected_drugs, model_name, prob, risk_class, shap_plot_buf=None, language="Chinese"):
    """ç”Ÿæˆ PDF æŠ¥å‘Š"""
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)

    # æ³¨å†Œå­—ä½“
    has_font = register_chinese_font()
    font_name = 'ChineseFont' if has_font else 'Helvetica'

    styles = getSampleStyleSheet()

    # è‡ªå®šä¹‰æ ·å¼
    title_style = ParagraphStyle(
        'TitleStyle',
        parent=styles['Title'],
        fontName=font_name,
        fontSize=24,
        leading=30,
        alignment=1 # Center
    )

    header_style = ParagraphStyle(
        'HeaderStyle',
        parent=styles['Heading2'],
        fontName=font_name,
        fontSize=14,
        leading=20,
        textColor=colors.darkblue
    )

    normal_style = ParagraphStyle(
        'NormalStyle',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=10,
        leading=14
    )

    story = []

    # 1. æ ‡é¢˜
    if language == "Chinese":
        title_text = "éª¨é«“æŠ‘åˆ¶é£é™©é¢„æµ‹æŠ¥å‘Š"
    else:
        title_text = "Bone Marrow Suppression Risk Prediction Report"
    story.append(Paragraph(title_text, title_style))
    story.append(Spacer(1, 20))

    # 2. é¢„æµ‹ç»“æœæ‘˜è¦
    if language == "Chinese":
        summary_text = "é¢„æµ‹ç»“æœæ‘˜è¦"
        model_label = "é¢„æµ‹æ¨¡å‹"
        score_label = "é£é™©è¯„åˆ†"
        class_label = "é£é™©ç±»åˆ«"
        high_risk_text = "é«˜é£é™© (High Risk)"
        low_risk_text = "ä½é£é™© (Low Risk)"
    else:
        summary_text = "Prediction Summary"
        model_label = "Prediction Model"
        score_label = "Risk Score"
        class_label = "Risk Category"
        high_risk_text = "High Risk"
        low_risk_text = "Low Risk"

    story.append(Paragraph(summary_text, header_style))
    risk_text = high_risk_text if risk_class == 1 else low_risk_text

    result_data = [
        [model_label, model_name],
        [score_label, f"{prob:.4f}"],
        [class_label, risk_text]
    ]

    t_result = Table(result_data, colWidths=[150, 300])
    t_result.setStyle(TableStyle([
        ('FONTNAME', (0, 0), (-1, -1), font_name),
        ('GRID', (0, 0), (-1, -1), 1, colors.grey),
        ('BACKGROUND', (0, 0), (0, -1), colors.lightgrey),
        ('Padding', (0, 0), (-1, -1), 12),
    ]))
    story.append(t_result)
    story.append(Spacer(1, 20))

    # 3. æ‚£è€…ä¿¡æ¯
    if language == "Chinese":
        patient_info_text = "æ‚£è€…åŸºæœ¬ä¿¡æ¯"
        gender_label = "æ€§åˆ«"
        age_label = "å¹´é¾„"
        stage_label = "ä¸´åºŠåˆ†æœŸ"
        drug_label = "è¯ç‰©æ–¹æ¡ˆ"
        no_drugs_text = "æ— "
        male_text = "ç”·"
        female_text = "å¥³"
    else:
        patient_info_text = "Patient Basic Information"
        gender_label = "Gender"
        age_label = "Age"
        stage_label = "Clinical Stage"
        drug_label = "Treatment Plan"
        no_drugs_text = "None"
        male_text = "Male"
        female_text = "Female"

    story.append(Paragraph(patient_info_text, header_style))
    p_info = [
        [gender_label, female_text if patient_data.get('gender') == 1 else male_text],
        [age_label, str(patient_data.get('age', 'N/A'))],
        [stage_label, str(patient_data.get('clinic_stage', 'N/A'))],
        [drug_label, ", ".join(selected_drugs) if selected_drugs else no_drugs_text]
    ]
    t_info = Table(p_info, colWidths=[150, 300])
    t_info.setStyle(TableStyle([
        ('FONTNAME', (0, 0), (-1, -1), font_name),
        ('GRID', (0, 0), (-1, -1), 0.5, colors.lightgrey),
    ]))
    story.append(t_info)
    story.append(Spacer(1, 20))

    # 4. SHAP åˆ†æå›¾ (Force Plot)
    if language == "Chinese":
        shap_text = "ç‰¹å¾é‡è¦æ€§åˆ†æ (SHAP Force Plot)"
        no_shap_text = "æœªç”Ÿæˆ SHAP å›¾åƒ"
    else:
        shap_text = "Feature Importance Analysis (SHAP Force Plot)"
        no_shap_text = "SHAP plot not generated"

    story.append(Paragraph(shap_text, header_style))
    if shap_plot_buf:
        shap_plot_buf.seek(0)
        # Force Plot é€šå¸¸æ¯”è¾ƒå®½ï¼Œè®¾ç½®åˆé€‚çš„å®½é«˜
        img = ReportLabImage(shap_plot_buf, width=540, height=200)
        story.append(img)
    else:
        story.append(Paragraph(no_shap_text, normal_style))

    doc.build(story)
    buffer.seek(0)
    return buffer.getvalue()

# ==========================================
# 4. æ ¸å¿ƒé€»è¾‘ï¼šæ•°æ®åŠ è½½ä¸å¤„ç†
# ==========================================

@st.cache_resource
def load_resources():
    """åŠ è½½æ‰€æœ‰èµ„æºï¼šæ˜ å°„è¡¨ã€Scalerã€æ¨¡å‹ç­‰"""
    try:
        # 1. è¯ç‰©æ˜ å°„ - ä¿ç•™ <RT>ï¼Œå»é™¤ PAD/UNK
        drug_df = pd.read_csv(f"{WORKING_DIR}/drug_category_index_clean.csv")
        # ä½¿ç”¨è‹±æ–‡è¯ç‰©åç§°ä½œä¸ºæ ‡å‡†ï¼ˆæ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨è‹±æ–‡åï¼‰
        drug_mapping = drug_df[~drug_df['Drug_Name(En)'].isin(['<PAD>', '<UNK>'])]

        # 2. ç‰¹å¾åç§°
        feature_names = joblib.load(f"{WORKING_DIR}/lightgbm_feature_names.joblib")

        # 3. æ ‡å‡†åŒ–å™¨ (Scaler)
        # scaler ç”¨äºæ ‡å‡†åŒ–è¿ç»­å˜é‡
        # scaler_continuous_features.joblib æ˜¯ç‰¹å¾ååˆ—è¡¨
        scaler = joblib.load(f"{WORKING_DIR}/scaler_continuous.joblib")
        scale_cols = joblib.load(f"{WORKING_DIR}/scaler_continuous_features.joblib")

        # 4. MultiLabelBinarizer
        mlb_drug = joblib.load(f"{WORKING_DIR}/mlb_drug.joblib")
        mlb_category = joblib.load(f"{WORKING_DIR}/mlb_category.joblib")

        # 5. æ¨¡å‹
        models = {
            "Hb": joblib.load(f"{WORKING_DIR}/Hb_LightGBM_Calibrated.joblib"),
            "PLT": joblib.load(f"{WORKING_DIR}/PLT_LightGBM_Calibrated.joblib"),
            "WBC_Neut": joblib.load(f"{WORKING_DIR}/WBC_Neut_LightGBM_Calibrated.joblib")
        }

        return drug_mapping, feature_names, scaler, scale_cols, mlb_drug, mlb_category, models
    except Exception as e:
        st.error(f"èµ„æºåŠ è½½å¤±è´¥: {str(e)}")
        st.error(traceback.format_exc())
        return None, None, None, None, None, None, None

def process_drug_features(selected_drugs, drug_mapping, mlb_drug, mlb_category):
    """
    å¤„ç†è¯ç‰©ç‰¹å¾ï¼š
    1. æ˜ å°„ ID å¹¶è¿›è¡Œå¤šçƒ­ç¼–ç 
    2. è®¡ç®—å½“å‰è¯ç‰©æ–¹æ¡ˆçš„ is_immuno, is_target, is_rt, is_chemo
    æ³¨æ„ï¼šcum_ ç³»åˆ—ç‰¹å¾ç”±ç”¨æˆ·ä¸Šä¼ ï¼Œä¸åœ¨æ­¤è®¡ç®—
    """
    drug_ids = []
    category_ids = []

    # ç»Ÿè®¡é‡åˆå§‹åŒ– (ä»…ç”¨äºè®¡ç®— is_ æ ‡å¿—ä½)
    current_stats = {
        'is_immuno': 0, 'is_target': 0, 'is_rt': 0, 'is_chemo': 0
    }

    if not selected_drugs:
        drug_encoded = mlb_drug.transform([[]])
        category_encoded = mlb_category.transform([[]])
        return drug_encoded, category_encoded, current_stats

    # ä¸´æ—¶çš„è®¡æ•°å™¨ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦ > 0
    count_immuno = 0
    count_target = 0
    count_rt = 0
    count_chemo = 0

    for drug in selected_drugs:
        row = drug_mapping[drug_mapping['Drug_Name(En)'] == drug]
        if not row.empty:
            d_id = int(row['Drug_ID'].iloc[0])
            c_id = int(row['Category_ID'].iloc[0])
            c_name = row['Category_Name'].iloc[0]

            drug_ids.append(d_id)
            category_ids.append(c_id)

            # é€»è¾‘ï¼šå– '_' å‰ç¼€
            # ç‰¹æ®Šæƒ…å†µï¼šRT æ²¡æœ‰ä¸‹åˆ’çº¿ï¼Œç›´æ¥ç­‰äº RT
            prefix = c_name.split('_')[0]

            if prefix == 'Immuno': count_immuno += 1
            if prefix == 'Target': count_target += 1
            if prefix == 'RT' or c_name == 'RT': count_rt += 1
            if prefix == 'Chemo':  count_chemo += 1

    # ç”Ÿæˆæ ‡å¿—ä½
    current_stats['is_immuno'] = 1 if count_immuno > 0 else 0
    current_stats['is_target'] = 1 if count_target > 0 else 0
    current_stats['is_rt'] = 1 if count_rt > 0 else 0
    current_stats['is_chemo'] = 1 if count_chemo > 0 else 0

    # å¤šçƒ­ç¼–ç 
    drug_encoded = mlb_drug.transform([drug_ids])
    category_encoded = mlb_category.transform([category_ids])

    return drug_encoded, category_encoded, current_stats

def prepare_input_vector(df, selected_drugs, drug_mapping, feature_names, scaler, scale_cols, mlb_drug, mlb_category, manual_features):
    """
    å‡†å¤‡è¾“å…¥å‘é‡
    è¿”å›: (standardized_df, original_values_dict)
    """
    # 1. åŸºç¡€æ•°æ®å¤åˆ¶ (æ¥è‡ªä¸Šä¼ çš„ CSV)
    # ç¡®ä¿åŒ…å«äº† cum_chemo, cum_rt, cum_target, cum_immuno, is_first_cycle, age ç­‰
    data = df.iloc[0].to_dict()
    original_values = data.copy()  # ä¿å­˜åŸå§‹å€¼ç”¨äºSHAPæ˜¾ç¤º

    # 2. è¦†ç›–/æ·»åŠ æ‰‹åŠ¨é€‰æ‹©çš„ç‰¹å¾ (gender, stages, ABO)
    data.update(manual_features)
    original_values.update(manual_features)

    # ABO ç‹¬çƒ­ç¼–ç  (ABO_A, ABO_B ...)
    abo = data.get('ABO', 'A') # è¿™é‡Œçš„ ABO æ¥è‡ª manual_features
    for t in ['A', 'B', 'O', 'AB', 'æœªæŸ¥']:
        data[f'ABO_{t}'] = 1 if abo == t else 0
        original_values[f'ABO_{t}'] = 1 if abo == t else 0

    # 3. è¯ç‰©å¤„ç† (è·å– embedding å’Œå½“æ¬¡è¯ç‰©å±æ€§)
    drug_enc, cat_enc, drug_stats = process_drug_features(selected_drugs, drug_mapping, mlb_drug, mlb_category)

    # å°† is_immuno ç­‰æ›´æ–°åˆ° data ä¸­ (è¦†ç›– CSV ä¸­å¯èƒ½å­˜åœ¨çš„ç©ºå€¼æˆ–æ—§å€¼)
    data.update(drug_stats)
    original_values.update(drug_stats)

    # 4. æ ‡å‡†åŒ–å¤„ç†
    if scaler is not None and scale_cols is not None:
        try:
            # æ„å»ºå¾…æ ‡å‡†åŒ–çš„ DataFrame
            # æ³¨æ„ï¼šå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ fit æ—¶çš„ç‰¹å¾é¡ºåº (å³ scale_cols ä¸­çš„é¡ºåº)
            vals_to_scale = {}
            for col in scale_cols:
                # è½¬ float
                v = data.get(col, 0.0)
                try: v = float(v)
                except: v = 0.0
                vals_to_scale[col] = [v]

            df_scale = pd.DataFrame(vals_to_scale, columns=scale_cols)
            scaled_vals_matrix = scaler.transform(df_scale)

            # å°†æ ‡å‡†åŒ–åçš„å€¼æ›´æ–°å› data
            # scaled_vals_matrix shape (1, N)
            for i, col in enumerate(scale_cols):
                data[col] = scaled_vals_matrix[0][i]

        except Exception as e:
            st.warning(f"æ ‡å‡†åŒ–è¿‡ç¨‹å‡ºç°è­¦å‘Š: {e}")
            # ç»§ç»­æ‰§è¡Œï¼Œä½¿ç”¨åŸå§‹å€¼

    # 5. æ„å»ºæ•°å€¼éƒ¨åˆ†å‘é‡ (LightGBM ç‰¹å¾é¡ºåº)
    # éœ€è¦ä¸¥æ ¼æŒ‰ç…§ feature_names çš„é¡ºåºæ„å»º
    n_drug_feats = len(mlb_drug.classes_)
    n_cat_feats = len(mlb_category.classes_)

    # æ•°å€¼ç‰¹å¾æ˜¯ feature_names å»æ‰åéƒ¨çš„ drug å’Œ category
    numeric_feat_names = feature_names[:-(n_drug_feats + n_cat_feats)]

    num_vals = []
    for col in numeric_feat_names:
        # ä» data ä¸­è·å– (æ­¤æ—¶å·²ç»æ˜¯æ ‡å‡†åŒ–åçš„å€¼)
        val = data.get(col, 0.0)
        try:
            val = float(val)
        except:
            val = 0.0
        num_vals.append(val)

    numeric_array = np.array(num_vals).reshape(1, -1)

    # 6. æœ€ç»ˆæ‹¼æ¥
    final_vector = np.hstack([numeric_array, drug_enc, cat_enc])

    # ç”Ÿæˆå¸¦åˆ—åçš„ DataFrame (LightGBM éœ€è¦åˆ—ååŒ¹é…)
    final_df = pd.DataFrame(final_vector, columns=feature_names)

    return final_df, original_values

def generate_test_csv():
    """
    ç”ŸæˆåŒ…å«æ‰€æœ‰å¿…éœ€åˆ—çš„æµ‹è¯• CSV (åŸºäº Web_test.csv çš„çœŸå®æ ·æœ¬)
    """
    # æ¥è‡ª debug åˆ†æçš„çœŸå®ç¬¬2è¡Œæ•°æ®ç»“æ„
    # åŒ…å« cum_* å’Œ is_first_cycle
    test_data = {
        'age': 27.0,
        'is_drinking': 1,
        'is_smoking': 1,
        'base_ALB': 46.4,
        'base_ALB/GLO': 1.6,
        'base_ALT': 83.3,
        'base_AST': 46.1,
        'base_AST/ALT': 0.6,
        'base_Baso': 0.0,
        'base_Baso%': 0.3,
        'base_Ca': 2.21,
        'base_Cl-': 100.2,
        'base_Crea': 67.0,
        'base_DBIL': 6.2,
        'base_Eos': 0.0,
        'base_Eos%': 0.1,
        'base_GLO': 29.8,
        'base_Hb': 157.0,
        'base_Hct': 45.4,
        'base_IBIL': 11.2,
        'base_K+': 3.9,
        'base_Lymph': 1.4,
        'base_Lymph%': 19.3,
        'base_MCH': 29.4,
        'base_MCHC': 346.0,
        'base_MCV': 85.0,
        'base_MPV': 10.6,
        'base_Mg2+': 0.86,
        'base_Mono': 0.4,
        'base_Mono%': 0.4, # ä¿®æ­£
        'base_Na+': 137.9,
        'base_Neut': 5.6,
        'base_Neut%': 75.2,
        'base_P': 1.15,
        'base_P-LCR%': 30.1,
        'base_PCT': 0.28, # ä¿®æ­£
        'base_PDW': 12.3,
        'base_PLT': 266.0,
        'base_RBC': 5.34,
        'base_RDW-CV': 12.6,
        'base_RDW-SD': 38.6,
        'base_TBIL': 17.4,
        'base_TP': 76.2,
        'base_UA': 365.0,
        'base_Urea': 4.1,
        'base_WBC': 7.4,
        # prev_nadir cols (ç®€åŒ–ä¸º0æˆ–åˆç†å€¼)
        'prev_nadir_ALB': 0,'prev_nadir_ALB/GLO':0,'prev_nadir_ALT':0,'prev_nadir_AST':0,
        'prev_nadir_AST/ALT':0,'prev_nadir_Baso':0,'prev_nadir_Baso%':0,'prev_nadir_Ca':0,
        'prev_nadir_Cl-':0,'prev_nadir_Crea':0,'prev_nadir_DBIL':0,'prev_nadir_Eos':0,
        'prev_nadir_Eos%':0,'prev_nadir_GLO':0,'prev_nadir_Hb':0,'prev_nadir_Hct':0,
        'prev_nadir_IBIL':0,'prev_nadir_K+':0,'prev_nadir_Lymph':0,'prev_nadir_Lymph%':0,
        'prev_nadir_MCH':0,'prev_nadir_MCHC':0,'prev_nadir_MCV':0,'prev_nadir_MPV':0,
        'prev_nadir_Mg2+':0,'prev_nadir_Mono':0,'prev_nadir_Mono%':0,'prev_nadir_Na+':0,
        'prev_nadir_Neut':0,'prev_nadir_Neut%':0,'prev_nadir_P':0,'prev_nadir_P-LCR%':0,
        'prev_nadir_PCT':0,'prev_nadir_PDW':0,'prev_nadir_PLT':0,'prev_nadir_RBC':0,
        'prev_nadir_RDW-CV':0,'prev_nadir_RDW-SD':0,'prev_nadir_TBIL':0,'prev_nadir_TP':0,
        'prev_nadir_UA':0,'prev_nadir_Urea':0,'prev_nadir_WBC':0,
        # å…³é”®çš„ cum_ ç‰¹å¾
        'cum_chemo': 1.0,
        'cum_target': 1.0,
        'cum_rt': 1.0,
        'cum_immuno': 0.0,
        'is_first_cycle': 1
    }

    df = pd.DataFrame([test_data])
    return df.to_csv(index=False).encode('utf-8')

# ==========================================
# 5. ä¸»åº”ç”¨é€»è¾‘ (Main)
# ==========================================

def main():
    # çŠ¶æ€åˆå§‹åŒ–
    if "data" not in st.session_state: st.session_state.data = None
    if "result" not in st.session_state: st.session_state.result = None
    if "language" not in st.session_state: st.session_state.language = "Chinese"

    # è¯­è¨€åˆ‡æ¢
    lang_col1, lang_col2, lang_col3 = st.columns([1, 1, 4])
    with lang_col1:
        if st.button("ğŸ‡¨ğŸ‡³ ä¸­æ–‡"):
            st.session_state.language = "Chinese"
            st.rerun()
    with lang_col2:
        if st.button("ğŸ‡ºğŸ‡¸ English"):
            st.session_state.language = "English"
            st.rerun()

    # æ ¹æ®è¯­è¨€è®¾ç½®æ ‡é¢˜
    if st.session_state.language == "Chinese":
        st.title("ğŸ¥ éª¨é«“æŠ‘åˆ¶é£é™©é¢„æµ‹ç³»ç»Ÿ")
    else:
        st.title("ğŸ¥ Bone Marrow Suppression Risk Prediction System")

    # 1. èµ„æºåŠ è½½
    drug_map, feat_names, scaler, scale_cols, mlb_d, mlb_c, models = load_resources()

    if drug_map is None:
        st.stop()

    # 2. ä¾§è¾¹æ ï¼šç”Ÿæˆæµ‹è¯•æ•°æ®
    with st.sidebar:
        if st.session_state.language == "Chinese":
            st.header("ğŸ›  æµ‹è¯•å·¥å…·")
            if st.button("ç”Ÿæˆæµ‹è¯•æ‚£è€…CSV"):
                csv_data = generate_test_csv()
                st.download_button("ğŸ“¥ ä¸‹è½½ test_patient.csv", csv_data, "test_patient.csv", "text/csv")
                st.info("å·²ç”ŸæˆåŒ…å« cum_chemo ç­‰å¿…è¦åˆ—çš„çœŸå®æµ‹è¯•æ•°æ®")
        else:
            st.header("ğŸ›  Test Tools")
            if st.button("Generate Test Patient CSV"):
                csv_data = generate_test_csv()
                st.download_button("ğŸ“¥ Download test_patient.csv", csv_data, "test_patient.csv", "text/csv")
                st.info("Generated real test data containing required columns like cum_chemo")

    # 3. æ­¥éª¤ä¸€ï¼šä¸Šä¼ æ•°æ®
    col1, col2 = st.columns(2)
    with col1:
        if st.session_state.language == "Chinese":
            st.subheader("1. ä¸Šä¼ æ‚£è€…æŒ‡æ ‡ (CSV)")
            uploaded = st.file_uploader("é€‰æ‹©CSVæ–‡ä»¶", type="csv")
            if uploaded:
                st.session_state.data = pd.read_csv(uploaded)
                st.success(f"å·²åŠ è½½: {len(st.session_state.data)} è¡Œæ•°æ®")

                # ç®€å•æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ (å¯é€‰)
                req_cols = ['cum_chemo', 'cum_rt', 'is_first_cycle']
                missing = [c for c in req_cols if c not in st.session_state.data.columns]
                if missing:
                    st.warning(f"è­¦å‘Š: ä¸Šä¼ æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼Œå¯èƒ½å¯¼è‡´é¢„æµ‹ä¸å‡†: {missing}")
        else:
            st.subheader("1. Upload Patient Metrics (CSV)")
            uploaded = st.file_uploader("Select CSV file", type="csv")
            if uploaded:
                st.session_state.data = pd.read_csv(uploaded)
                st.success(f"Loaded: {len(st.session_state.data)} rows of data")

                # Simple column check (optional)
                req_cols = ['cum_chemo', 'cum_rt', 'is_first_cycle']
                missing = [c for c in req_cols if c not in st.session_state.data.columns]
                if missing:
                    st.warning(f"Warning: Uploaded file is missing the following columns, which may affect prediction accuracy: {missing}")

    # 4. æ­¥éª¤äºŒï¼šUI è¾“å…¥ç‰¹å¾
    with col2:
        if st.session_state.language == "Chinese":
            st.subheader("2. è¡¥å……ä¸´åºŠä¿¡æ¯")
            gender = st.selectbox("æ€§åˆ«", ["ç”·", "å¥³"], index=0) # 0=ç”·
            gender_val = 0 if gender == "ç”·" else 1

            c_t = st.selectbox("cT åˆ†æœŸ", [0, 1, 2, 3, 4], index=3)
            c_n = st.selectbox("cN åˆ†æœŸ", [0, 1, 2, 3], index=3)
            c_m = st.selectbox("cM åˆ†æœŸ", [0, 1], index=0)

            # ç®€å•è®¡ç®— clinic_stage (ç¤ºä¾‹: 1-4)
            clinic_stage = min(4, max(1, c_t + c_n))
            st.caption(f"è‡ªåŠ¨è®¡ç®—ä¸´åºŠåˆ†æœŸ: {clinic_stage}")

            abo = st.selectbox("ABO è¡€å‹", ["A", "B", "O", "AB", "æœªæŸ¥"], index=0)
        else:
            st.subheader("2. Supplement Clinical Information")
            gender = st.selectbox("Gender", ["Male", "Female"], index=0) # 0=Male
            gender_val = 0 if gender == "Male" else 1

            c_t = st.selectbox("cT Stage", [0, 1, 2, 3, 4], index=3)
            c_n = st.selectbox("cN Stage", [0, 1, 2, 3], index=3)
            c_m = st.selectbox("cM Stage", [0, 1], index=0)

            # Simple clinic_stage calculation (example: 1-4)
            clinic_stage = min(4, max(1, c_t + c_n))
            st.caption(f"Automatically calculated clinical stage: {clinic_stage}")

            abo = st.selectbox("ABO Blood Type", ["A", "B", "O", "AB", "Not Checked"], index=0)

    # 5. æ­¥éª¤ä¸‰ï¼šè¯ç‰©é€‰æ‹©
    if st.session_state.language == "Chinese":
        st.subheader("3. æ²»ç–—æ–¹æ¡ˆ")
        # é»˜è®¤é€‰ä¸­ é¡ºé“‚ å’Œ å¤šè¥¿ä»–èµ›
        default_drugs = ["Cisplatin", "Docetaxel"]
    else:
        st.subheader("3. Treatment Plan")
        # Default selected: Cisplatin and Docetaxel
        default_drugs = ["Cisplatin", "Docetaxel"]

    # æ ¹æ®è¯­è¨€é€‰æ‹©æ˜¾ç¤ºçš„è¯ç‰©åç§°åˆ—
    if st.session_state.language == "Chinese":
        drug_display_names = sorted(drug_map['Drug_Name(Cn)'].dropna().unique())
        drug_en_names = sorted(drug_map['Drug_Name(En)'].dropna().unique())
        # åˆ›å»ºä¸­è‹±æ–‡æ˜ å°„
        drug_cn_to_en = dict(zip(drug_map['Drug_Name(Cn)'], drug_map['Drug_Name(En)']))
        drug_en_to_cn = dict(zip(drug_map['Drug_Name(En)'], drug_map['Drug_Name(Cn)']))
    else:
        drug_display_names = sorted(drug_map['Drug_Name(En)'].dropna().unique())
        drug_en_names = drug_display_names
        drug_cn_to_en = {}
        drug_en_to_cn = {}

    # é»˜è®¤é€‰ä¸­ é¡ºé“‚ å’Œ å¤šè¥¿ä»–èµ›
    pre_select_display = []
    for drug in default_drugs:
        if st.session_state.language == "Chinese":
            # æ‰¾åˆ°å¯¹åº”çš„ä¸­æ–‡å
            cn_name = drug_en_to_cn.get(drug, drug)
            if cn_name in drug_display_names:
                pre_select_display.append(cn_name)
        else:
            if drug in drug_display_names:
                pre_select_display.append(drug)

    selected_drugs_display = st.multiselect(
        "é€‰æ‹©åŒ–ç–—è¯ç‰© (åŒ…å« <RT>)" if st.session_state.language == "Chinese" else "Select chemotherapy drugs (including <RT>)",
        drug_display_names,
        default=pre_select_display
    )

    # å°†æ˜¾ç¤ºåç§°è½¬æ¢å›è‹±æ–‡åç”¨äºæ¨¡å‹å¤„ç†
    if st.session_state.language == "Chinese":
        selected_drugs = [drug_cn_to_en.get(d, d) for d in selected_drugs_display]
    else:
        selected_drugs = selected_drugs_display

    # 6. é¢„æµ‹ä¸ç»“æœ
    st.divider()
    if st.session_state.language == "Chinese":
        model_choice = st.radio("é€‰æ‹©é¢„æµ‹æ¨¡å‹", ["Hb", "PLT", "WBC_Neut"], horizontal=True)
        analyze_button_text = "ğŸš€ å¼€å§‹åˆ†æ"
    else:
        model_choice = st.radio("Select Prediction Model", ["Hb", "PLT", "WBC_Neut"], horizontal=True)
        analyze_button_text = "ğŸš€ Start Analysis"

    if st.button(analyze_button_text, type="primary"):
        if st.session_state.data is None:
            if st.session_state.language == "Chinese":
                st.error("è¯·å…ˆä¸Šä¼ CSVæ–‡ä»¶")
            else:
                st.error("Please upload a CSV file first")
            return

        try:
            # å‡†å¤‡è¾“å…¥
            manual_feats = {
                "gender": gender_val,
                "c_t_stage": c_t,
                "c_n_stage": c_n,
                "c_m_stage": c_m,
                "clinic_stage": clinic_stage,
                "ABO": abo
            }

            X_input, original_values = prepare_input_vector(
                st.session_state.data,
                selected_drugs,
                drug_map,
                feat_names,
                scaler,
                scale_cols,
                mlb_d,
                mlb_c,
                manual_feats
            )

            # æ¨¡å‹é¢„æµ‹
            model = models[model_choice]
            # Predict Proba
            probs = model.predict_proba(X_input)
            prob = probs[0][1] # å–æ­£ç±»æ¦‚ç‡

            # å®šä¹‰ Cutoff é˜ˆå€¼
            cutoffs = {
                "Hb": 0.0076,
                "PLT": 0.0093,
                "WBC_Neut": 0.0039
            }
            cutoff = cutoffs.get(model_choice, 0.5)

            risk_class = 1 if prob >= cutoff else 0

            # SHAP è§£é‡Š (Force Plot)
            # æ³¨æ„ï¼šä½¿ç”¨ base_model è¿›è¡Œè§£é‡Š
            if hasattr(model, 'base_model'):
                core_model = model.base_model
            else:
                core_model = model

            explainer = shap.TreeExplainer(core_model)
            shap_values = explainer.shap_values(X_input)

            # ç»Ÿä¸€å¤„ç† SHAP è¾“å‡º
            if isinstance(shap_values, list):
                # Binary classification produces list [negative, positive]
                # LightGBM é€šå¸¸è¿”å› [array(N,M), array(N,M)]
                sv = shap_values[1][0] # æ­£ç±», ç¬¬0ä¸ªæ ·æœ¬ -> vector
                ev = explainer.expected_value[1]
            else:
                sv = shap_values[0] # TreeExplainer æœ‰æ—¶ç›´æ¥è¿”å› matrix
                ev = explainer.expected_value

            # ä¿å­˜ç»“æœåˆ° Session
            st.session_state.result = {
                "prob": prob,
                "class": risk_class,
                "sv": sv,
                "ev": ev,
                "input_df": X_input,
                "original_values": original_values,
                "model": model_choice,
                "cutoff": cutoff
            }

        except Exception as e:
            st.error(f"é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {str(e)}")
            st.error(traceback.format_exc())

    # 7. ç»“æœå±•ç¤ºåŒº
    if st.session_state.result:
        res = st.session_state.result

        if st.session_state.language == "Chinese":
            st.subheader("ğŸ“Š åˆ†æç»“æœ")
            risk_text = "é«˜é£é™©" if res['class']==1 else "ä½é£é™©"
            safety_text = "-å®‰å…¨" if res['class']==0 else "+æ³¨æ„"
            model_text = f"æ¨¡å‹: {res['model']}"
            shap_title = "ç‰¹å¾å½±å“åˆ†æ (Force Plot)"
            pdf_button_text = "ğŸ“„ ä¸‹è½½å®Œæ•´æŠ¥å‘Š (PDF)"
        else:
            st.subheader("ğŸ“Š Analysis Results")
            risk_text = "High Risk" if res['class']==1 else "Low Risk"
            safety_text = "-Safe" if res['class']==0 else "+Caution"
            model_text = f"Model: {res['model']}"
            shap_title = "Feature Impact Analysis (Force Plot)"
            pdf_button_text = "ğŸ“„ Download Full Report (PDF)"

        c1, c2, c3 = st.columns(3)
        if st.session_state.language == "Chinese":
            c1.metric("é£é™©è¯„åˆ†", f"{res['prob']:.4f}")
            c2.metric("é£é™©ç±»åˆ«", f"{risk_text} (CutOff: {res['cutoff']:.3f})", delta=safety_text, delta_color="inverse")
        else:
            c1.metric("Risk Score", f"{res['prob']:.4f}")
            c2.metric("Risk Category", f"{risk_text} (CutOff: {res['cutoff']:.3f})", delta=safety_text, delta_color="inverse")
        c3.info(model_text)

        # SHAP Force Plot
        st.subheader(shap_title)

        # ç”Ÿæˆ Force Plot
        try:
            # åˆ›å»ºåŸå§‹å€¼çš„DataFrameç”¨äºSHAPæ˜¾ç¤º
            original_values = res['original_values']
            feature_names = res['input_df'].columns.tolist()
            original_values_list = []
            for col in feature_names:
                val = original_values.get(col, 0.0)
                try:
                    val = float(val)
                except:
                    val = 0.0
                original_values_list.append(val)
            original_values_series = pd.Series(original_values_list, index=feature_names)

            plt.figure(figsize=(20, 4))
            # matplotlib=True ä¼šç›´æ¥åœ¨å½“å‰ figure ä¸Šç”»å›¾
            shap.force_plot(
                res['ev'],
                res['sv'],
                original_values_series,
                matplotlib=True,
                show=False,
                text_rotation=45
            )

            # ä¿å­˜åˆ° Buffer
            force_plot_buf = io.BytesIO()
            plt.savefig(force_plot_buf, format='png', bbox_inches='tight', dpi=150)
            force_plot_buf.seek(0)

            # æ˜¾ç¤º
            st.image(force_plot_buf, caption="SHAP Force Plot", use_column_width=True)

            # PDF ä¸‹è½½
            pdf_bytes = create_pdf_report(
                st.session_state.data.iloc[0].to_dict(), # ç®€åŒ–çš„æ‚£è€…ä¿¡æ¯
                selected_drugs,
                res['model'],
                res['prob'],
                res['class'],
                shap_plot_buf=force_plot_buf, # ä¼ å…¥ buffer
                language=st.session_state.language
            )

            st.download_button(
                pdf_button_text,
                pdf_bytes,
                f"Risk_Report_{res['model']}.pdf",
                "application/pdf",
                type="primary"
            )
        except Exception as e:
            st.error(f"ç»˜å›¾å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
